<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="description" content=""> <meta name="keywords" content=""> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>NeRF-US</title> <link rel="icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-DHVEPP2GQR"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-DHVEPP2GQR");</script> <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> <link rel="stylesheet" href="../assets/css/bulma.min.css"> <link rel="stylesheet" href="../assets/css/bulma-carousel.min.css"> <link rel="stylesheet" href="../assets/css/bulma-slider.min.css"> <link rel="stylesheet" href="../assets/css/fontawesome.all.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> <link rel="stylesheet" href="../assets/css/nerfies_general.css"> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> <script defer src="../assets/js/fontawesome.all.min.js"></script> <script src="../assets/js/bulma-carousel.min.js"></script> <script src="../assets/js/bulma-slider.min.js"></script> <script src="../assets/js/nerfies_index.js"></script> <script src="../assets/js/nerfies_comparision.js"></script> <script>function toggleCodeBlock(){var e=document.getElementById("bashCodeBlock");"none"===e.style.display?e.style.display="block":e.style.display="none"}</script> <style>h1 img{width:50px;height:auto;vertical-align:middle}table{width:100%;border-collapse:collapse;margin:20px 0;font-family:system-ui,-apple-system,sans-serif}th,td{padding:12px;text-align:left}th{background-color:#f5f5f5;font-weight:600;border-bottom:2px solid #ddd}tr:hover{background-color:#f0f0f0}.section-header{background-color:#e0e0e0;font-weight:bold;border-bottom:1px solid #ddd;border-top:1px solid #ddd}.subsection{padding-left:24px}</style> </head> <body> <nav class="navbar" role="navigation" aria-label="main navigation"> <div class="navbar-brand"> <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false"> <span aria-hidden="true"></span> </a> </div> <div class="navbar-menu"> <div class="navbar-start" style="flex-grow: 1; justify-content: center;"> <a class="navbar-item" href="../"> <span class="icon"> <i class="fas fa-home"></i> </span> </a> <div class="navbar-item has-dropdown is-hoverable"> <a class="navbar-link"> More Research </a> <div class="navbar-dropdown"> <a class="navbar-item" href="https://see2sound.github.io" rel="external nofollow noopener" target="_blank"> SEE-2-SOUND </a> </div> </div> </div> </div> </nav> <section class="hero"> <div class="hero-body"> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column has-text-centered"> <h1 class="title is-1 publication-title">NeRF-US<span>ðŸ‘¤ðŸ‘¤:</span> Neural Radiance Fields for Accurate Ultrasound Imaging in the Wild</h1> <div class="is-size-5 publication-authors"> <span class="author-block"> <a href="https://www.cs.toronto.edu/~rishit">Rishit Dagli</a><sup>1,2</sup>, <a href="https://hibiat.github.io/cv1/" rel="external nofollow noopener" target="_blank">Atsuhiro Hibi</a><sup>2,3,4</sup>, <a href="https://www.cs.toronto.edu/~rahulgk/">Rahul G. Krishnan</a><sup>1,5</sup>, <a href="https://scholar.google.com/citations?user=c-KHCzEAAAAJ&amp;hl=en&amp;oi=ao" rel="external nofollow noopener" target="_blank">Pascal Tyrrell</a><sup>2,4,6</sup> </span> </div> <div class="is-size-5 publication-authors"> <span class="author-block"> Departments of <sup>1</sup> Computer Science; <sup>2</sup> Medical Imaging, University of Toronto, Canada<br> <sup>3</sup> Division of Neurosurgery, St Michael's Hospital, Unity Health Toronto, Canada<br> <sup>4</sup> Institute of Medical Science; Departments of <sup>5</sup> Laboratory Medicine and Pathobiology; <sup>6</sup> Statistical Sciences, University of Toronto, Canada </span> </div> <div class="column has-text-centered"> <div class="publication-links"> <span class="link-block"> <a href="/~rishit/https://openreview.net/pdf?id=WNwMLWvzwB" class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Paper</span> </a> </span> <span class="link-block"> <a href="https://arxiv.org/abs/2408.10258" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <span class="icon"> <i class="ai ai-arxiv"></i> </span> <span>arXiv</span> </a> </span> <span class="link-block"> <a href="https://github.com/Rishit-dagli/nerf-us" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span> <span class="link-block"> <a href="https://huggingface.co/datasets/rishitdagli/us-in-the-wild" class="external-link button is-normal is-rounded is-dark" rel="external nofollow noopener" target="_blank"> <span class="icon"> <i class="fas fa-database"></i> </span> <span>Data</span> </a> </span> </div> </div> </div> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="content"> <section class="hero"> <div class="container"> <h4 class="subtitle has-text-centered"> <span style="color: #4DAF50"> <span class="dnerf">NeRF-US</span> trains a NeRF on sound fields. </span> </h4> </div> </section> <section class="hero teaser"> <div class="container is-max-desktop"> <div class="hero-body"> <img src="../assets/img/nerf-us/teaser.png" alt="NeRF-US Teaser Image" style="max-width: 100%; margin: 0 auto;"> </div> </div> </section> <section class="hero is-light is-small"> <div class="hero-body"> <div class="container"> <div id="results-carousel" class="carousel results-carousel"> <div class="item item-steve"> <video poster="" id="steve" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/results/converted_0.mp4" type="video/mp4"></source> </video> </div> <div class="item item-chair-tp"> <video poster="" id="chair-tp" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/results/converted_1.mp4" type="video/mp4"></source> </video> </div> <div class="item item-shiba"> <video poster="" id="shiba" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/results/converted_2.mp4" type="video/mp4"></source> </video> </div> <div class="item item-fullbody"> <video poster="" id="fullbody" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/results/converted_3.mp4" type="video/mp4"></source> </video> </div> <div class="item item-blueshirt"> <video poster="" id="blueshirt" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/results/converted_4.mp4" type="video/mp4"></source> </video> </div> <div class="item item-mask"> <video poster="" id="mask" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/results/converted_5.mp4" type="video/mp4"></source> </video> </div> </div> </div> </div> <h5 class="subtitle has-text-centered"> Novel view ultrasound renders from <span class="dnerf">NeRF-US</span>. </h5> </section> <p><br></p> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <h2>Abstract</h2> <div class="content has-text-justified"> Current methods for performing 3D reconstruction and novel view synthesis (NVS) in ultrasound imaging data often face severe artifacts when training NeRF-based approaches. The artifacts produced by current approaches differ from NeRF floaters in general scenes because of the unique nature of ultrasound capture. Furthermore, existing models fail to produce reasonable 3D reconstructions when ultrasound data is captured or obtained casually in uncontrolled environments, which is common in clinical settings. Consequently, existing reconstruction and NVS methods struggle to handle ultrasound motion, fail to capture intricate details, and cannot model transparent and reflective surfaces. In this work, we introduced NeRF-US, which incorporates 3D-geometry guidance for border probability and scattering density into NeRF training, while also utilizing ultrasound-specific rendering over traditional volume rendering. These 3D priors are learned through a diffusion model. Through experiments conducted on our new ``Ultrasound in the Wild'' dataset, we observed accurate, clinically plausible, artifact-free reconstructions. </div> </div> </div> <hr> <h2 id="motivation">Motivation</h2> <div style="display: flex; width: 100%;"> <div style="width: 75%; padding-right: 8px; text-align: left;"> There are a few challenges common when using previous medical NeRF methods and standard methods: the need for high-quality, diverse datasets, capturing intricate details like <span style="color:red">tissue interface locations</span> critical for medical diagnosis, accurately modeling transparent and reflective surfaces. There are quite a few <span style="color:red">NeRF artifacts</span> that appear when using these methods in the wild. In contrast to this, our approach (as shown) produces artifact-free reconstructions with minor details accurately reconstructed. </div> <div style="width: 15%; padding-left: 8px; text-align: right; display: flex; justify-content: center; align-items: center;"> <img src="../assets/img/nerf-us/param.png" alt="Showcasing boundaries." style="width: 100%; height: auto; max-width: 90%;"> </div> </div> <h2>How does <span class="dnerf">NeRF-US</span> work?</h2> <p>Our goal is to produce a 3D representation given a set of ultrasound images taken in the wild and their camera positions. The first step of our approach relies on the training of a <span style="color:red">3D diffusion model</span>, which can serve as geometric priors for our NeRF model. This diffusion model produces an 32 x 32 x 32 occupancy grid. To create this diffusion model, we finetune the 3D diffusion model on a small dataset of voxels around the human knee generated synthetically.</p> <div class="content has-text-justified"> <img src="../assets/img/nerf-us/diffusion.png" alt="How to create diffusion model?" style="max-width: 90%; margin: 0 auto;"> <p>Figure: An overview of how our diffusion model is fine-tuned, we use 32<sup>3</sup>-sized patches to LoRA-finetune a 3D diffusion model trained on ShapeNet.</p> We now train our NeRF model that takes in a 3D vector (denoting positions in 3D) and learns a 5D vector (attenuation, reflectance, border probability, scattering density, and scattering intensity). While training this NeRF, we run the outputs through the diffusion model and obtain <span style="color:red">guidance vectors</span> for <span style="color:red">border probability</span> and <span style="color:red">scattering density</span>. These are added to the photometric loss. We finally train the NeRF with this final loss we calculated. <div class="content has-text-justified"> <img src="../assets/img/nerf-us/methods.png" alt="How to train our model?" style="max-width: 90%; margin: 0 auto;"> <p>Figure: An overview of how our method works. We train a NeRF model that uses ultrasound rendering to convert the representations into a 2D image after which we infer through a 3D diffusion model which has geometry priors through which we calculate a modified loss definition to train the NeRF.</p> <h2 id="visual-results">Visual Results</h2> <section class="section"> <div class="container is-max-desktop "> <div class=" has-text-centered"> <div class="columns is-centered"> <div class="column"> <div class="content"> <div class="columns is-centered"> <div class="column is-full-width"> <div id="example1" class="bal-container-small"> <div class="bal-after"> <img src="../assets/img/nerf-us/results/interactive/ours_0.jpg"> <div class="bal-afterPosition afterLabel" style="z-index:1;"> Ours </div> </div> <div class="bal-before" style="width:96.4968152866242%;"> <div class="bal-before-inset" style="width: 512px;"> <img src="../assets/img/nerf-us/results/interactive/nfacto_0.jpg"> <div class="bal-beforePosition beforeLabel"> Nerfacto [Tancik 2023] </div> </div> </div> <div class="bal-handle" style="left:96.4968152866242%;"> <span class=" handle-left-arrow"></span> <span class="handle-right-arrow"></span> </div> </div> <div id="example2" class="bal-container-small"> <div class="bal-after"> <img src="../assets/img/nerf-us/results/interactive/ours_1.jpg"> <div class="bal-afterPosition afterLabel"> Ours </div> </div> <div class="bal-before" style="width: 50%;"> <div class="bal-before-inset" style="width: 512px;"> <img src="../assets/img/nerf-us/results/interactive/nfacto_1.jpg"> <div class="bal-beforePosition beforeLabel"> Nerfacto [Tancik 2023] </div> </div> </div> <div class="bal-handle" style="left: 50%;"> <span class=" handle-left-arrow"></span> <span class="handle-right-arrow"></span> </div> </div> <div id="example3" class="bal-container-small"> <div class="bal-after"> <img src="../assets/img/nerf-us/results/interactive/ours_2.jpg"> <div class="bal-afterPosition afterLabel"> Ours </div> </div> <div class="bal-before" style="width: 50%;"> <div class="bal-before-inset" style="width: 512px;"> <img src="../assets/img/nerf-us/results/interactive/nfacto_2.jpg"> <div class="bal-beforePosition beforeLabel"> Nerfacto [Tancik 2023] </div> </div> </div> <div class="bal-handle" style="left: 50%;"> <span class=" handle-left-arrow"></span> <span class="handle-right-arrow"></span> </div> </div> </div> </div> </div> </div> <div class="column"> <div class="columns is-centered"> <div class="column content"> <div id="example4" class="bal-container-small"> <div class="bal-after"> <img src="../assets/img/nerf-us/results/interactive/ours_0.jpg"> <div class="bal-afterPosition afterLabel" style="z-index:1;"> Ours </div> </div> <div class="bal-before" style="width:62.10191082802548%;"> <div class="bal-before-inset" style="width: 512px;"> <img src="../assets/img/nerf-us/results/interactive/un_0.jpg"> <div class="bal-beforePosition beforeLabel"> Ultra-NeRF [Wysocki 2024] </div> </div> </div> <div class="bal-handle" style="left:62.10191082802548%;"> <span class=" handle-left-arrow"></span> <span class="handle-right-arrow"></span> </div> </div> <div id="example5" class="bal-container-small"> <div class="bal-after"> <img src="../assets/img/nerf-us/results/interactive/ours_1.jpg"> <div class="bal-afterPosition afterLabel" style="z-index:1;"> Ours </div> </div> <div class="bal-before" style="width:56.77179962894249%;"> <div class="bal-before-inset" style="width: 512px;"> <img src="../assets/img/nerf-us/results/interactive/un_1.jpg"> <div class="bal-beforePosition beforeLabel"> Ultra-NeRF [Wysocki 2024] </div> </div> </div> <div class="bal-handle" style="left:56.77179962894249%;"> <span class=" handle-left-arrow"></span> <span class="handle-right-arrow"></span> </div> </div> <div id="example6" class="bal-container-small"> <div class="bal-after"> <img src="../assets/img/nerf-us/results/interactive/ours_2.jpg"> <div class="bal-afterPosition afterLabel" style="z-index:1;"> Ours </div> </div> <div class="bal-before" style="width:56.77179962894249%;"> <div class="bal-before-inset" style="width: 512px;"> <img src="../assets/img/nerf-us/results/interactive/un_2.jpg"> <div class="bal-beforePosition beforeLabel"> Ultra-NeRF [Wysocki 2024] </div> </div> </div> <div class="bal-handle" style="left:56.77179962894249%;"> <span class=" handle-left-arrow"></span> <span class="handle-right-arrow"></span> </div> </div> </div> </div> </div> </div> </div> </div> </section> <script>new BeforeAfter({id:"#example1"}),new BeforeAfter({id:"#example2"}),new BeforeAfter({id:"#example3"}),new BeforeAfter({id:"#example4"}),new BeforeAfter({id:"#example5"}),new BeforeAfter({id:"#example6"});</script> <div class="content has-text-justified"> <img src="../assets/img/nerf-us/results.png" style="max-width: 80%; margin: 0 auto;"> <p>Figure: <b>Qualitative Results.</b> We demonstrate the results of our method and compare it qualitatively with Nerfacto [1], Gaussian Splatting [3], and Ultra-NeRF [2]. Our approach, NeRF-US, produces accurate and high-quality reconstructions as compared to the baseline models on novel views (<b>best viewed with zoom</b>).</p> </div> <div class="content has-text-justified"> <img src="../assets/img/nerf-us/resultsdepth.png" alt="Depth comparisons" style="max-width: 80%; margin: 0 auto;"> <p>Figure: <b>Qualitative Results.</b> We demonstrate the results of depth maps produced from our method and compare them qualitatively with Nerfacto [1], Gaussian Splatting [3], and Ultra-NeRF [2] (<b>best viewed in color and with zoom</b>).</p> </div> <script>$(window).on("load",function(){$("#loading").hide()});</script> <h2 id="ultrasound-in-the-wild-dataset">Ultrasound in the wild Dataset</h2> Here we show some instances of our new ultrasound in the wild dataset, we limit the visualizations of the dataset to the first 10 seconds of some of the scenes in our dataset. For visualization, we pre-process these videos with a script.<br><br> <div class="content"> <button class="button is-black is-block" onclick="toggleCodeBlock()">Show pre-processing script</button> <div id="bashCodeBlock" style="display: none;"> <pre><code class="language-bash">#!/bin/bash

TARGET_BITRATE="1700k"

for i in {0..6}
do
  inputFile="converted_${i}.mp4"
  outputFile="temp_${inputFile}"

  echo "Processing $inputFile..."

  ffmpeg -i "$inputFile" -vcodec h264 -acodec aac -b:v $TARGET_BITRATE -strict -2 "$outputFile"

  if [ $? -eq 0 ]; then
    mv "$outputFile" "$inputFile"
    echo "$inputFile has been successfully converted to a browser-compatible format and overwritten."
  else
    echo "An error occurred while converting $inputFile."
  fi
done

echo "All files have been processed."
</code></pre> </div> </div> <section class="hero is-light is-small"> <div class="hero-body"> <div class="container"> <div id="results-carousel" class="carousel results-carousel"> <div class="item item-steve"> <video poster="" id="steve" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_0.mp4" type="video/mp4"></source> </video> </div> <div class="item item-chair-tp"> <video poster="" id="chair-tp" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_1.mp4" type="video/mp4"></source> </video> </div> <div class="item item-shiba"> <video poster="" id="shiba" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_2.mp4" type="video/mp4"></source> </video> </div> <div class="item item-fullbody"> <video poster="" id="fullbody" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_3.mp4" type="video/mp4"></source> </video> </div> <div class="item item-blueshirt"> <video poster="" id="blueshirt" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_4.mp4" type="video/mp4"></source> </video> </div> <div class="item item-mask"> <video poster="" id="mask" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_5.mp4" type="video/mp4"></source> </video> </div> <div class="item item-coffee"> <video poster="" id="coffee" autoplay="" controls="" muted="" loop="" playsinline="" height="100%"> <source src="../assets/img/nerf-us/dataset/converted_6.mp4" type="video/mp4"></source> </video> </div> </div> </div> </div> <h5 class="subtitle has-text-centered"> Examples from our ultrasound in the wild dataset. </h5> </section> <h2 id="related-links">Related Links</h2> The following works were mentioned on this page:<br><br> [1] Tancik, Matthew, et al. "Nerfstudio: A modular framework for neural radiance field development." ACM SIGGRAPH 2023 Conference Proceedings. 2023.<br><br> [2] Wysocki, Magdalena, et al. "Ultra-nerf: neural radiance fields for ultrasound imaging." Medical Imaging with Deep Learning. PMLR, 2024.<br><br> [3] Kerbl, Bernhard, et al. "3d gaussian splatting for real-time radiance field rendering." ACM Transactions on Graphics 42.4 (2023): 1-14. <h2 id="citation">Citation</h2> <div style="position: relative;"> <pre><code id="citationCode">@misc{dagli2024nerfusremovingultrasoundimaging,
      title={NeRF-US: Removing Ultrasound Imaging Artifacts from Neural Radiance Fields in the Wild}, 
      author={Rishit Dagli and Atsuhiro Hibi and Rahul G. Krishnan and Pascal N. Tyrrell},
      year={2024},
      eprint={2408.10258},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.10258}, 
}</code></pre> <button class="button is-small is-dark" onclick="copyCitation()" style="position: absolute; top: 10px; right: 10px;"> <span class="icon"> <i class="fas fa-copy"></i> </span> </button> </div> <script>function copyCitation(){var t=document.getElementById("citationCode").innerText;navigator.clipboard.writeText(t)}</script> <h2 id="acknowledgements">Acknowledgements</h2> This research was enabled in part by support provided by the <a href="https://alliancecan.ca/" rel="external nofollow noopener" target="_blank">Digital Research Alliance of Canada</a>. This research was supported in part with Cloud TPUs from <a href="https://sites.research.google/trc/about/" rel="external nofollow noopener" target="_blank">Google's TPU Research Cloud (TRC)</a>. The resources used to prepare this research were provided, in part, by the Province of Ontario, the Government of Canada through CIFAR, and companies sponsoring the <a href="https://vectorinstitute.ai/partnerships/current-partners/" rel="external nofollow noopener" target="_blank">Vector Institute</a>. </div> </div> </div> </div> </section> <footer class="footer"> <div class="container"> <div class="content has-text-centered"> <a class="icon-link" href="blank"> <i class="fas fa-file-pdf"></i> </a> <a class="icon-link" href="https://github.com/Rishit-dagli" disabled rel="external nofollow noopener" target="_blank"> <i class="fab fa-github"></i> </a> </div> <div class="columns is-centered"> <div class="column is-8"> <div class="content"> <p> Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io" rel="external nofollow noopener" target="_blank">NeRFies</a>. </p> <p> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>. </p> </div> </div> </div> </div> </footer> </body> </html>